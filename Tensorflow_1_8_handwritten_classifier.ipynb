{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow_1.8_handwritten_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUta65LOat1r"
      },
      "source": [
        "Tensorflow 1.8 simple hand written digits classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6156XfhSWgWV",
        "outputId": "ae3472bd-b880-4262-dd20-fb04f0f9fc42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install tensorflow==1.8"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/c6/d08f7c549330c2acc1b18b5c1f0f8d9d2af92f54d56861f331f372731671/tensorflow-1.8.0-cp36-cp36m-manylinux1_x86_64.whl (49.1MB)\n",
            "\u001b[K     |████████████████████████████████| 49.1MB 87kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (1.18.5)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (1.33.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (0.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (3.12.4)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (0.3.3)\n",
            "Collecting tensorboard<1.9.0,>=1.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/a6/0ae6092b7542cfedba6b2a1c9b8dceaf278238c39484f3ba03b03f07803c/tensorboard-1.8.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 38.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (0.35.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow==1.8) (50.3.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8) (3.3.2)\n",
            "Collecting bleach==1.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
            "Collecting html5lib==0.9999999\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 40.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.9.0,>=1.8.0->tensorflow==1.8) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.9.0,>=1.8.0->tensorflow==1.8) (3.3.1)\n",
            "Building wheels for collected packages: html5lib\n",
            "  Building wheel for html5lib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for html5lib: filename=html5lib-0.9999999-cp36-none-any.whl size=107220 sha256=62f5fe51d6d7966465c45edcf825fb4fbaad0be13fb1401e8d8cf46aaec2ba93\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n",
            "Successfully built html5lib\n",
            "Installing collected packages: html5lib, bleach, tensorboard, tensorflow\n",
            "  Found existing installation: html5lib 1.0.1\n",
            "    Uninstalling html5lib-1.0.1:\n",
            "      Successfully uninstalled html5lib-1.0.1\n",
            "  Found existing installation: bleach 3.2.1\n",
            "    Uninstalling bleach-3.2.1:\n",
            "      Successfully uninstalled bleach-3.2.1\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed bleach-1.5.0 html5lib-0.9999999 tensorboard-1.8.0 tensorflow-1.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SEwxTsTW3hs",
        "outputId": "b0a4de65-aab7-41ea-d4e6-6f5fe1e86440",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMEdgzhlXPl0",
        "outputId": "87194e13-f954-4c40-a2e7-0771f8647e5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def preprocess_data(im, label):\n",
        "    im = tf.cast(im, tf.float32)\n",
        "    im = im / 127.5\n",
        "    im = im - 1\n",
        "    im = tf.reshape(im, [-1])\n",
        "    return im, label\n",
        "\n",
        "def data_layer(data_tensor, num_threads=8, prefetch_buffer=100, batch_size=32):\n",
        "    with tf.variable_scope(\"data\"):\n",
        "        dataset = tf.data.Dataset.from_tensor_slices(data_tensor)\n",
        "        dataset = dataset.shuffle(buffer_size=60000).repeat()\n",
        "        dataset = dataset.map(preprocess_data, num_parallel_calls=num_threads)\n",
        "        dataset = dataset.batch(batch_size)\n",
        "        dataset = dataset.prefetch(prefetch_buffer)\n",
        "        iterator = dataset.make_one_shot_iterator()\n",
        "    return iterator\n",
        "\n",
        "def model(input_layer, num_classes=10):\n",
        "    with tf.variable_scope(\"model\"):\n",
        "        net = tf.layers.dense(input_layer, 512)\n",
        "        net = tf.nn.relu(net)\n",
        "        net = tf.layers.dense(net, num_classes)\n",
        "    return net\n",
        "\n",
        "def loss_functions(logits, labels, num_classes=10):\n",
        "    with tf.variable_scope(\"loss\"):\n",
        "        target_prob = tf.one_hot(labels, num_classes)\n",
        "        total_loss = tf.losses.softmax_cross_entropy(target_prob, logits)\n",
        "    return total_loss\n",
        "\n",
        "def optimizer_func(total_loss, global_step, learning_rate=0.1):\n",
        "    with tf.variable_scope(\"optimizer\"):\n",
        "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "        optimizer = optimizer.minimize(total_loss, global_step=global_step)\n",
        "    return optimizer\n",
        "\n",
        "def performance_metric(logits, labels):\n",
        "    with tf.variable_scope(\"performance_metric\"):\n",
        "        preds = tf.argmax(logits, axis=1)\n",
        "        labels = tf.cast(labels, tf.int64)\n",
        "        corrects = tf.equal(preds, labels)\n",
        "        accuracy = tf.reduce_mean(tf.cast(corrects, tf.float32))\n",
        "    return accuracy\n",
        "\n",
        "def train(data_tensor):\n",
        "    global_step = tf.Variable(1, dtype=tf.int32, trainable=False, name=\"iter_number\")\n",
        "\n",
        "    # training graph\n",
        "    images, labels = data_layer(data_tensor).get_next()\n",
        "    logits = model(images)\n",
        "    loss = loss_functions(logits, labels)\n",
        "    optimizer = optimizer_func(loss, global_step)\n",
        "    accuracy = performance_metric(logits, labels)\n",
        "\n",
        "    # start training\n",
        "    num_iter = 10000\n",
        "    log_iter = 1000\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        streaming_loss = 0\n",
        "        streaming_accuracy = 0\n",
        "\n",
        "        for i in range(1, num_iter + 1):\n",
        "            _, loss_batch, acc_batch = sess.run([optimizer, loss, accuracy])\n",
        "            streaming_loss += loss_batch\n",
        "            streaming_accuracy += acc_batch\n",
        "            if i % log_iter == 0:\n",
        "                print(\"Iteration: {}, Streaming loss: {:.2f}, Streaming accuracy: {:.2f}\"\n",
        "                        .format(i, streaming_loss/log_iter, streaming_accuracy/log_iter))\n",
        "                streaming_loss = 0\n",
        "                streaming_accuracy = 0\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # It's very easy to load the MNIST dataset through the Keras module.\n",
        "    # Keras is a high-level neural network API that has become a part of TensorFlow since version 1.2.\n",
        "    # Therefore, we don't need to install Keras separately.\n",
        "    # In the upcoming lectures we will also see how to load and preprocess custom data.\n",
        "    data_train, data_val = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "    # The training set has 60,000 samples where each sample is a 28x28 grayscale image.\n",
        "    # Each one of these samples have a single label Similarly the validation set has 10,000 images and corresponding labels.\n",
        "    # We can verify this by printing the shapes of the loaded tensors\n",
        "    print(data_train[0].shape, data_train[1].shape, data_val[0].shape, data_val[1].shape)\n",
        "\n",
        "    # Let the training begin!\n",
        "    train(data_tensor=data_train)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n",
            "Iteration: 1000, Streaming loss: 0.43, Streaming accuracy: 0.87\n",
            "Iteration: 2000, Streaming loss: 0.19, Streaming accuracy: 0.95\n",
            "Iteration: 3000, Streaming loss: 0.14, Streaming accuracy: 0.96\n",
            "Iteration: 4000, Streaming loss: 0.12, Streaming accuracy: 0.96\n",
            "Iteration: 5000, Streaming loss: 0.10, Streaming accuracy: 0.97\n",
            "Iteration: 6000, Streaming loss: 0.09, Streaming accuracy: 0.97\n",
            "Iteration: 7000, Streaming loss: 0.08, Streaming accuracy: 0.97\n",
            "Iteration: 8000, Streaming loss: 0.07, Streaming accuracy: 0.98\n",
            "Iteration: 9000, Streaming loss: 0.07, Streaming accuracy: 0.98\n",
            "Iteration: 10000, Streaming loss: 0.06, Streaming accuracy: 0.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imzly87xXpR_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}